---
title: "Introduction to dblinkR"
author: "Neil Marchant"
date: "6 March 2020"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Introduction to dblinkR}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width=7, 
  fig.height=5
)
```

Connect to Spark in pseudocluster mode
```{r}
library(stringr)
library(dplyr)
library(tidyr)
library(ggplot2)
library(sparklyr)
library(dblinkR)

sc <- spark_connect(master = "local", version = "2.3.1")
```

Save results in the following directory
```{r}
projectPath <- paste0(getwd(), "/") # current working directory
```

Experiment with RLdata500
```{r}
records <- RLdata500
records['file_id'] <- 1
records['rec_id'] <- seq_len(nrow(records))
records['ent_id'] <- identity.RLdata500
records <- lapply(records, as.character) %>% as.data.frame(stringsAsFactors = FALSE)
```

Define model parameters
```{r}
distortionPrior <- BetaRV(1, 50)
levSim <- LevenshteinSimFn(threshold = 7.0, maxSimilarity =  10.0)
attributeSpecs <- list(
  fname_c1 = Attribute(levSim, distortionPrior),
  lname_c1 = Attribute(levSim, distortionPrior),
  by = CategoricalAttribute(distortionPrior),
  bm = CategoricalAttribute(distortionPrior),
  bd = CategoricalAttribute(distortionPrior)
)
```

Don't use partitioning, since this is such a small data set
```{r}
partitioner <- KDTreePartitioner(0, c('fname_c1', 'bd'))
```

Initialize Markov chain and run inference
```{r}
state <- initializeState(sc, records, attributeSpecs, recIdColname = 'rec_id',
                         partitioner = partitioner, populationSize = 500L,
                         fileIdColname = 'file_id', randomSeed = 1,
                         maxClusterSize = 10L)

result <- runInference(state, projectPath, sampleSize = 100, burninInterval = 100)
```

Alternatively load results from disk
```{r}
result <- loadResult(sc, projectPath)
```


Can examine diagnostics
```{r}
diagnostics <- loadDiagnostics(sc, projectPath)

ggplot(diagnostics, aes(x=iteration, y=numObservedEntities)) + 
  geom_line() + 
  labs(title = 'Trace plot: # entity clusters', x = 'Iteration', 
       y = '# clusters')

diagnostics %>%
  select(iteration, starts_with("aggDist")) %>%
  gather(attribute, numDistortions, starts_with("aggDist")) %>%
  mutate(attribute = str_match(attribute, "^aggDist(.+)")[,2],
         numDistortions = numDistortions / nrow(records)) %>% 
  ggplot(aes(x=iteration, y=numDistortions)) +  
  geom_line(aes(colour = attribute)) + 
  labs(title = 'Trace plot: attribute distortion', x = 'Iteration', 
       y = '% distorted', colour = 'Attribute')

ggplot(diagnostics, aes(x=iteration, y=logLikelihood)) + 
  geom_line() + 
  labs(title = 'Trace plot: log-likelihood (unnormalized)', x = 'Iteration', 
       y = 'log-likelihood')
```

```{r}
linkageChain <- dblinkR::loadLinkageChain(sc, projectPath)
clustSizeDist <- clusterSizeDistribution(linkageChain)
ggplot(clustSizeDist, aes(x=iteration, y=frequency)) + 
  geom_line(aes(colour = clusterSize)) + 
  labs(title = 'Trace plot: cluster size distribution', x = 'Iteration', 
       y = 'Frequency', colour = 'Cluster size')

partSizes <- partitionSizes(linkageChain)
ggplot(partSizes, aes(x=iteration, y=size)) + 
  geom_line(aes(colour = partitionId)) + 
  labs(title = 'Trace plot: partition sizes', x = 'Iteration', y = 'Size', 
       colour = 'Partition')
```


Finally, do evaluation
```{r}
predClusters <- dblinkR::sharedMostProbableClusters(linkageChain) %>% collect()
trueClusters <- exchangeableER::membershipToClusters(records$ent_id, ids = records$rec_id)
predMatches <- exchangeableER::clustersToPairs.Clusters(predClusters)
trueMatches <- exchangeableER::clustersToPairs.Clusters(trueClusters)
numRecords <- nrow(records)
conMat <- exchangeableER::confusionMatrix(predMatches, trueMatches, numRecords*(numRecords - 1)/2)
print(exchangeableER::pairwiseMetrics(conMat))
```




